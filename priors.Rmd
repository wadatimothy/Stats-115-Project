---
title: "project115"
author: "Alfonso Vieyra"
date: "3/18/2024"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bayesrules)
library(dplyr)
library(tidyverse)
library(readxl)

vgames_df <- read.csv("./video_games.csv")
```

### Clean data 

```{r}
# reading the data in as a dataframe but then reassign data frame with the 
# variables = review_score, console, length, genres, multiplayer, multiplatform, 
# online, sales where response is review score

vgames_df <- vgames_df %>% 
         rename(review_score = Metrics.Review.Score, console = Release.Console, 
         length = Length.All.PlayStyles.Average, genres = Metadata.Genres, 
         sales = Metrics.Sales, rating = Release.Rating)

vgames_df <- vgames_df %>% 
  select(review_score, console, length, genres, sales, rating)

head(vgames_df)
```

```{r}
# Changes genres into a single genre
for (row in 1:nrow(vgames_df)) {
  genres <- strsplit(vgames_df$genres[row], split = ",", fixed = TRUE)[[1]]
  if(length(genres) > 0) { 
    i <- sample(length(genres), 1) 
    vgames_df$genres[row] <- genres[i]
  }
}

head(vgames_df)
```


```{r}
colSums(is.na(vgames_df))
```

```{r}
ggplot(vgames_df, aes(x = review_score)) +
  geom_histogram()
```

## Developing an informative prior

Below are 3 data sets and their respective games list that contain review 
scores. They come from 3 very large media platforms that are well known for 
video game reviews and therefore serve as an excellent way to develop some prior 
expectations.

Two data sets are from Kaggle where the data scourced is from Metacritic and 
Steam.The other dataset is user generated based on IGN's review scores. The 
Metacritic data set contains a metascore based on journalist reviews and a user 
score based on user reviews. The Steam data set contains only user review scores. 
The IGN dataset contains review scores from its own journalists. 

Link to metacritic data set: 
https://www.kaggle.com/datasets/henrylin03/metacritic-games-user-reviews-and-metascores

Link to steam data set:
https://www.kaggle.com/datasets/andrewmvd/steam-reviews

Link to IGN data set:
https://www.dropbox.com/s/09sh15zbtwg9eu3/gamedata.xlsx

### Metacritic 

```{r}
# Removing rows that do not feature a recorded review score or is na
metacritic_df <- read.csv("../prior_datasets/metacritic_game_reviews.csv")
metacritic_df <- drop_na(metacritic_df)

# removed rows in metascore that do not have a digit and converted column to 
# integer
metacritic_df <- metacritic_df[metacritic_df$metascore != "tbd", ]
metacritic_df$metascore <- as.integer(metacritic_df$metascore)

# removed rows in user score that do not have a digit and converted column to 
# integer
metacritic_df <- metacritic_df[metacritic_df$userscore != "tbd", ]
metacritic_df$userscore <- as.integer(metacritic_df$userscore)

# convert userscore to scale of 0 - 100 (note:user score 0 - 10 default)
metacritic_df$userscore <- round(metacritic_df$userscore * 10, 0)
```

#### Journalist score

```{r}
ggplot(metacritic_df, aes(x = metascore)) +
  geom_histogram()
```

```{r}
summary(metacritic_df$metascore)
```

```{r}
metacritic_df %>%
  summarise(variance = var(metascore), standard_deviation =  sd(metascore))
```


```{r}
# See platform specific average review ratings
metascore_platforms <- metacritic_df %>%
  group_by(platform) %>%
  summarise(average_platform_metascore = mean(metascore))

summary(metascore_platforms$average_platform_metascore)
```


```{r}
ggplot(metascore_platforms, aes(x = average_platform_metascore)) + 
  geom_histogram(binwidth = 1)
```


#### User score

```{r}
ggplot(metacritic_df, aes(x = userscore)) +
  geom_histogram(binwidth = 10)
```

```{r}
summary(metacritic_df$userscore)
```

```{r}
metacritic_df %>%
  summarise(variance = var(userscore), standard_deviation =  sd(userscore))
```


```{r}
userscore_platforms <- metacritic_df %>%
  group_by(platform) %>%
  summarise(average_platform_userscore = mean(userscore))

summary(userscore_platforms)
```

```{r}
ggplot(metacritic_platforms_user, aes(x = average_platform_userscore)) + 
  geom_histogram(binwidth = 1)
```


### Steam review scores

```{r}
steam_df <- read.csv("../prior_datasets/steam_reviews_dataset.csv")
steam_df <- drop_na(steam_df)
```

```{r}
# Group and add reviews based on positive sentiment

steam_df <- steam_df %>%
  group_by(app_name) %>%
  summarise(score = round((sum(review_score == 1) / n())*100), 0)
```

```{r}
ggplot(steam_df, aes(x = score)) +
  geom_histogram()
```


```{r}
summary(steam_df$score)
```


```{r}
steam_df %>%
  summarise(variance = var(score), standard_deviation =  sd(score))
```


### IGN review scores 


```{r}
ign_df <- read_excel("../prior_datasets/ign_game_reviews.xlsx")
ign_df <- drop_na(ign_df)
```


```{r}
# Changes genres into a single genre
for (row in 1:nrow(ign_df)) {
  genres <- strsplit(ign_df$Genre[row], split = ",", fixed = TRUE)[[1]]
  if(length(genres) > 0) { 
    i <- sample(length(genres), 1) 
    ign_df$Genre[row] <- genres[i]
  }
}

# Scale to a score between 0 - 100
ign_df$Score = ign_df$Score * 10

head(ign_df)
```


```{r}
ign_genres <- ign_df %>% 
  group_by(Genre) %>%
  summarise(Score = mean(Score))

summary(ign_genres)
```

```{r}
ign_genres %>% 
  summarise(var = var(Score), sd = sd(Score))
```

## Chosen Pior 

### intercept prior
We see that the average reviews for Metacritic's journalist score and user score 
are approximately 70.84 and 64.19, respectively. Furthermore, Steam's user score 
mean was 72.73. Taking the mean of these respective scores we get a score of 
69.25.

We get a variance of 161.5068	for Metacritics metascore, 207.0729	for 
Metacritic's userscore and 459.8953 for Steam's userscore. The overall mean of 
the variance of these three scores is 276.1583. 

Overall then, our stated prior would include a mean of 69.25 and a variance of 
276.1583. 

**intercept prior**: N(u = 69.25, sigma = 16.618)

### platform prior
Metacritic's average review across different platforms highlights a 
difference in scores based on the platform. This could suggest that game review
scores can be helped estimated based on the console the game was on. Using the 
mean of these scores as our prior, we get 68.485 and using a rough std 
estimate of 76.16 - 61.83 / 4 = 3.5825.

**platform prior**: N(u = 68.485, sigma = 3.5825)

### Sales prior
Also, there is evidence based off reported findings from new press that sales 
is generally correlated with that of video game reviews. This is highlighted
in the following article [shacknews](https://www.shacknews.com/article/84203/higher-metacritic-scores-impact-game-sales-positively). In terms of sales, the mean sales for video games was roughly 
277,500 where sales for games rated 90+ were on the higher side of the curve vs
that of games rated less than a metascore of 30. Thus, for rough estimate which
can help give us an idea of the variability we expect, considering the range
of sales, we get that 800,000 - 10,000 / 4 = 197,500.

**Sales Prior**: N(u = 277,500, sigma = 197,500)

<<<<<<< HEAD
### Game Length 
Despite our inclusion of game length, current literature and reports [Video Game Length – Size Doesn’t Matter](https://gameswithtoasty.com/2022/01/04/video-game-length-size-doesnt-matter/) indicate 
that game length does not have any significant impact on the review rating of a 
game. Therefore, we will use a default weakly informative prior. 

**Game length Prior**: N(u = 0, sigma = 5)
=======
### Game Length & Rating
Despite our inclusion of game length and Rating, current literature and reports 
[Video Game Length – Size Doesn’t Matter](https://gameswithtoasty.com/2022/01/04/video-game-length-size-doesnt-matter/) indicate that game length does not have any significant impact on the review 
rating of a game. Likewise, the rating a game receives doesn't appear to have a 
great deal of prior information that would correlate with reviews scores.
Therefore, we will use a default weakly informative prior for both of these 
variables. 

**Game length Prior**: N(u = 0, sigma = 5)
**Rating Prior**: N(u = 0, sigma = 5)
>>>>>>> alfonso

### Genres

For game reviews by Genre provided by the ign data set, we get a normal prior of
**Genre Prior**: N(u = 65.81, sigma = 11.33086)
<<<<<<< HEAD

### Rating




=======



>>>>>>> alfonso
**Data:** \(Y_i| \beta_0, \beta_1\, \beta_2, \beta_3, \beta_4, \beta_5, \sigma\)
\(~ N(\mu_i, \sigma^2)\)  with \(\mu_i\ = \beta_0 + \beta_1Console_{i} + \beta_2Length_{i} 
+ \beta_3Genres_{i3} + \beta_4Sales_{i} +\beta_5Rating_{i}\)
